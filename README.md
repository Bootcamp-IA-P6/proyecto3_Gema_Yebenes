# Web Scraper Project

Un proyecto Django de web scraping automatizado que utiliza Selenium y Firefox en un contenedor Docker, con ejecuciÃ³n programada mediante cron.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un web scraper que:
- Extrae datos de sitios web usando Selenium con Firefox
- Guarda los datos en una base de datos SQLite
- Toma capturas de pantalla automÃ¡ticas
- Se ejecuta automÃ¡ticamente cada minuto mediante cron
- Funciona completamente dentro de un contenedor Docker

## ğŸš€ CaracterÃ­sticas

- **Scraping automatizado**: ExtracciÃ³n de tÃ­tulos y URLs de pÃ¡ginas web
- **Capturas de pantalla**: Almacenamiento de screenshots con timestamp
- **EjecuciÃ³n programada**: Cron job configurado para ejecutarse cada minuto
- **Dockerizado**: Totalmente containerizado para fÃ¡cil despliegue
- **Base de datos**: SQLite para almacenar datos scrapeados
- **Admin de Django**: Panel de administraciÃ³n para ver datos recolectados

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.12**
- **Django 6.0.1**
- **Selenium 4.40.0**
- **Firefox ESR** (headless)
- **GeckoDriver 0.35.0**
- **Docker & Docker Compose**
- **Cron**

## ğŸ“¦ Estructura del Proyecto

```
.
â”œâ”€â”€ scraper/                      # AplicaciÃ³n Django principal
â”‚   â”œâ”€â”€ management/
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”‚       â””â”€â”€ scrape.py        # Comando personalizado de scraping
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ scrape.py            # LÃ³gica de scraping con Selenium
â”‚   â”œâ”€â”€ models.py                # Modelo ScrapedData
â”‚   â””â”€â”€ admin.py                 # ConfiguraciÃ³n del admin
â”œâ”€â”€ webscraper_project/          # ConfiguraciÃ³n Django
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ screenshots/                 # Volumen para capturas de pantalla
â”œâ”€â”€ Dockerfile                   # ConfiguraciÃ³n del contenedor
â”œâ”€â”€ compose.yaml                 # OrquestaciÃ³n Docker
â”œâ”€â”€ cronfile                     # ConfiguraciÃ³n de cron
â”œâ”€â”€ requirements.txt             # Dependencias Python
â””â”€â”€ manage.py                    # CLI de Django
```

## ğŸ”§ InstalaciÃ³n y Uso

### Prerrequisitos

- Docker
- Docker Compose

### Pasos de instalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <tu-repositorio>
cd webscraper_project
```

2. **Construir y ejecutar el contenedor**
```bash
docker compose up --build
```

3. **El scraper se ejecutarÃ¡ automÃ¡ticamente cada minuto**

### Verificar funcionamiento

**Ver logs de cron:**
```bash
docker compose exec server tail -f /var/log/cron.log
```

**Acceder al contenedor:**
```bash
docker compose exec server bash
```

**Ver capturas de pantalla:**
Las capturas se guardan en `./screenshots/` en tu mÃ¡quina host

**Acceder a la base de datos:**
```bash
docker compose exec server python manage.py dbshell
```

## ğŸ¯ Comandos Ãštiles

### Ejecutar scraping manualmente
```bash
docker compose exec server python manage.py scrape
```

### Crear superusuario (para acceder al admin)
```bash
docker compose exec server python manage.py createsuperuser
```

### Ver logs del contenedor
```bash
docker compose logs -f server
```

### Reiniciar el contenedor
```bash
docker compose restart
```

## ğŸ“Š Acceso al Admin de Django

1. Crear superusuario (ver comando arriba)
2. Si deseas acceder al panel admin, modifica el `Dockerfile` para ejecutar el servidor Django:
```dockerfile
CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
```
3. Descomenta la lÃ­nea en `compose.yaml` para exponer el puerto
4. Accede a `http://localhost:8000/admin`

## ğŸ”„ ConfiguraciÃ³n de Cron

El archivo `cronfile` define la frecuencia de ejecuciÃ³n:
```
* * * * * /usr/local/bin/python /app/manage.py scrape >> /var/log/cron.log 2>&1
```

**Formato:** `minuto hora dÃ­a mes dÃ­a_semana comando`

**Ejemplos:**
- Cada minuto: `* * * * *`
- Cada hora: `0 * * * *`
- Cada dÃ­a a las 2 AM: `0 2 * * *`
- Cada lunes a las 9 AM: `0 9 * * 1`

## ğŸ› SoluciÃ³n de Problemas

### Cron no ejecuta el scraper
- Verificar logs: `docker compose exec server cat /var/log/cron.log`
- Verificar que cron estÃ© corriendo: `docker compose exec server ps aux | grep cron`

### Error con caracteres Windows en cronfile
El Dockerfile incluye: `RUN sed -i 's/\r$//' /etc/cron.d/scrape-cron`

### Permisos de escritura
Los directorios `/app` y `/app/screenshots` tienen permisos 777 para evitar problemas

### Firefox no se inicia
Verificar que todos los paquetes estÃ©n instalados correctamente en el Dockerfile

## ğŸ“ PersonalizaciÃ³n

### Cambiar URL objetivo
Edita `scraper/services/scrape.py`:
```python
url = "https://tu-sitio-web.com"
```

### Modificar selectores CSS
Edita los selectores en `scrape.py`:
```python
titles = driver.find_elements(By.CSS_SELECTOR, "tu-selector")
```

### Ajustar tiempo de espera
Modifica el timeout en `scrape.py`:
```python
WebDriverWait(driver, 10).until(...)  # Cambiar 10 por segundos deseados
```

## âš ï¸ Notas Importantes

- El proyecto usa **root** dentro del contenedor por simplicidad
- En producciÃ³n, considera usar un usuario no privilegiado
- La `SECRET_KEY` debe cambiarse en producciÃ³n
- `DEBUG = True` debe ser `False` en producciÃ³n
- Las capturas de pantalla se acumulan - implementa limpieza periÃ³dica si es necesario

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia que elijas especificar.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue primero para discutir los cambios propuestos.
